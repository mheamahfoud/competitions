{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "NrMNcI3ZczkS"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mheamahfoud/competitions/blob/main/Visual_Pollution_Detection_Using_Yolo_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visual Pollution Detection\n",
        "\n",
        "\n",
        "This solution  is based on the [YOLOv7 repository](https://github.com/WongKinYiu/yolov7) by WongKinYiu. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### **Steps Covered in this solution**\n",
        "\n",
        "To train our detector we take the following steps:\n",
        "\n",
        "* Install YOLOv7 dependencies\n",
        "* load dataset and anallysis\n",
        "* split dataset for training\n",
        "* Evaluate YOLOv7 performance\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Preparing a  Dataset\n",
        "\n",
        "In this notBook, we download dataset as zip and extract "
      ],
      "metadata": {
        "id": "3vDxGw6kAmnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "C9MBLAxpaadt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Global Variable"
      ],
      "metadata": {
        "id": "0XSKlUNQdKcb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#If you want to train model please change value of variable to True\n",
        "IS_Training=False"
      ],
      "metadata": {
        "id": "soLPEBIUdI9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load Libraries"
      ],
      "metadata": {
        "id": "Xbua6J7yGbTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "import cv2\n",
        "import PIL\n",
        "import matplotlib as mpl\n",
        "from matplotlib import pyplot as plt\n",
        "import glob\n",
        "import os ,shutil\n",
        "pd.set_option('display.max_columns', 10)\n",
        "from tqdm.auto import tqdm\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "from pandas.core.algorithms import unique\n",
        "from os import path        "
      ],
      "metadata": {
        "id": "zMnBGrt9-0Rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load dataset "
      ],
      "metadata": {
        "id": "XjtVaSCl-iNH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqxMqFM39yT6"
      },
      "outputs": [],
      "source": [
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_zip_path = 'path_to_dataset_zip'\n",
        "!unzip -q $dataset_zip_path -d /content/\n",
        "!rm $dataset_zip_path\n",
        "dataset_path='/content/dataset'"
      ],
      "metadata": {
        "id": "aHk4nUv1USTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Utils"
      ],
      "metadata": {
        "id": "mWST4DESJvh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#function for drawing box on a image\n",
        "def draw_boundbox(img, box):\n",
        "    x0,y0,x1,y1 = box[0], box[1], box[2], box[3]\n",
        "    color = (255, 0, 0)\n",
        "    img = cv2.rectangle(img, (x0, y0), (x1, y1), color,10)\n",
        "    return img\n",
        "\n",
        "def draw_boundboxes(img, boxes):\n",
        "    for box in boxes:\n",
        "        img = draw_boundbox(img, box)\n",
        "    return img\n",
        "\n",
        "##convert form [xmin ymin xmax ymax] to [x_centered, y_centered, width, height] normalized\n",
        "def convert_coordinates(size, box, scale):\n",
        "    assert scale > 0.86, \"scale is too small\"\n",
        "    dw = 1.0/size[0]\n",
        "    dh = 1.0/size[1]\n",
        "    x = (box[0]+box[1])/2.0\n",
        "    y = (box[2]+box[3])/2.0\n",
        "    w = scale * (box[1]-box[0])\n",
        "    h = scale * (box[3]-box[2])\n",
        "    x = x*dw\n",
        "    w = w*dw\n",
        "    y = y*dh\n",
        "    h = h*dh\n",
        "    return (x,y,w,h)\n",
        "\n",
        "#function to create.txt yolo format\n",
        "def csv_to_txt(data_set, out_path, class_labels, scale=1.0):\n",
        "    # Read Csv \n",
        "    df = data_set\n",
        "     # Group rows based on image_name because single file may have multiple annotations\n",
        "    for name, group in df.groupby('image_path'):\n",
        "        # Create filename\n",
        "        fname_out = os.path.join(out_path, name.split(\".\")[0] + '.txt')\n",
        "        # Open txt file to write\n",
        "        with open(fname_out, \"w\") as f:\n",
        "            # Iter through each bbox\n",
        "            for row_index, row in group.iterrows():\n",
        "                xmin = row['xmin']\n",
        "                ymin = row['ymin']\n",
        "                xmax = row['xmax']\n",
        "                ymax = row['ymax']\n",
        "                width = 1920\n",
        "                height = 1080\n",
        "                # Get label index\n",
        "                label_str = str(math.trunc(class_labels[row['name']]))\n",
        "                b = (float(xmin), float(xmax), float(ymin), float(ymax))\n",
        "                # Convert bbox from pascal voc format to yolo txt format\n",
        "                bb = convert_coordinates((width,height), b, scale)\n",
        "                # Write into file\n",
        "                f.write(label_str + \" \" + \" \".join([(\"%.6f\" % a) for a in bb]) + '\\n')\n",
        "\n",
        "\n",
        " #function to create dataset(train,valid)               \n",
        "def create_dataset(data,path_images,path_labels,dataset_path,class_labels=None):\n",
        "    #craete labels\n",
        "    if class_labels is not None:\n",
        "      csv_to_txt(data ,path_labels,class_labels)\n",
        "    #create images\n",
        "   # Path(path_images).mkdir(parents=True, exist_ok=True)\n",
        "    for image_path in list(data['image_path']):\n",
        "        src = os.path.join(f'{dataset_path}/images/{image_path}')\n",
        "        dst = os.path.join(f'{path_images}/{image_path}')\n",
        "       # print(path.exists(dst))\n",
        "        if not path.exists(dst) :\n",
        "               #print(path.exists(dst))\n",
        "               shutil.copy(src, dst)\n",
        "        \n",
        "        \n",
        "        \n",
        "def generate_images_path(dataset_path,data_type):\n",
        "    fname_out = os.path.join( custom_data_path, data_type + '.txt')\n",
        "    with open(fname_out, \"w\") as f:\n",
        "        for path in os.listdir(dataset_path):\n",
        "           # check if current path is a file\n",
        "\n",
        "           if os.path.isfile(os.path.join(dataset_path, path)):\n",
        "                f.write( os.path.join(dataset_path, path) + '\\n')\n",
        "\n",
        "\n",
        "font = {'family' : 'normal',\n",
        "        'weight' : 'bold',\n",
        "        'size'   : 12}\n",
        "\n",
        "plt.rc('font', **font)\n",
        "#function tp draw images with boxs\n",
        "def plotImagesAndLabels(dataset_path,dataset_filenames,dataset_label_box):\n",
        "    fig = plt.figure(figsize=(16, 16))\n",
        "    columns =3\n",
        "    rows = 3\n",
        "    index=1\n",
        "    \n",
        "    for k in range(9):\n",
        "        img_name = np.random.choice(list(dataset_filenames))\n",
        "        #print(img_name)\n",
        "        for item in dataset_label_box[img_name]:\n",
        "                test_img = cv2.cvtColor(cv2.imread( f'{dataset_path}/images/{img_name}', -1), cv2.COLOR_BGR2RGB)    \n",
        "                test_img_bb = draw_boundbox(test_img, item[2])\n",
        "                if index < 10 :\n",
        "                    fig.add_subplot(rows, columns, index)\n",
        "                    plt.imshow(test_img_bb)\n",
        "                    plt.title(item[1])\n",
        "                    plt.text(100, 100, img_name,)\n",
        "                    index+=1\n",
        "                break\n",
        "               # fig.add_subplot(rows, columns, k)\n",
        "                #plt.figure(figsize=(10, 10))\n",
        "            \n",
        "\n",
        "    \n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "E6AobZ_5JyJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Analysis Dataset"
      ],
      "metadata": {
        "id": "Gt7MOiURGJjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#original classes ordered by  depend on  train.csv\n",
        "orginal_classes = ['GRAFFITI',\n",
        "    'FADED_SIGNAGE',\n",
        "    'POTHOLES',                                                                                                                                                    \n",
        "    'GARBAGE',\n",
        "    'CONSTRUCTION_ROAD',\n",
        "    'BROKEN_SIGNAGE',\n",
        "    'BAD_STREETLIGHT',\n",
        "    'BAD_BILLBOARD',\n",
        "    'SAND_ON_ROAD',\n",
        "    'CLUTTER_SIDEWALK',\n",
        "    'UNKEPT_FACADE']\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mZU45IceGOug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dictiony class  map to  label (orginal dataset)\n",
        "orginal_class_map_label_dictionery = {idx: clc for idx, clc in enumerate(orginal_classes)}\n",
        "orginal_class_map_label_dictionery"
      ],
      "metadata": {
        "id": "VnF9wcOWH1hU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dictiony label   map to  class  (orginal dataset)\n",
        "orginal_label_map_class_dictionery = {clc: idx for idx, clc in enumerate(orginal_classes)}\n",
        "orginal_label_map_class_dictionery\n",
        "\n"
      ],
      "metadata": {
        "id": "CA3EZlhznzYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define df_dataset\n",
        "df_origin_dataset=pd.read_csv(f'{dataset_path}/train.csv')\n",
        "df_dataset = df_origin_dataset.copy()\n",
        "df_test=pd.read_csv(f\"{dataset_path}/test.csv\")\n",
        "dataset_filenames = df_dataset['image_path'].to_list()"
      ],
      "metadata": {
        "id": "TsVFhN-fH3Ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Check width and height o dataset"
      ],
      "metadata": {
        "id": "pLhZvVBeLwB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "width_ar=[];\n",
        "height_ar=[];\n",
        "for image_name in list(dataset_filenames):\n",
        "    img = Image.open(f'{dataset_path}/images/{image_name}')\n",
        "    width, height = img.size\n",
        "    width_ar.append(width)\n",
        "    height_ar.append(height)\n",
        "res_width = all(ele == 1920 for ele in width_ar)\n",
        "res_height = all(ele == 1080 for ele in height_ar)\n",
        "print(res_width)\n",
        "print(res_height)\n",
        "print(len(height_ar))"
      ],
      "metadata": {
        "id": "csrAskvkLxLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fix bounding boxes"
      ],
      "metadata": {
        "id": "FCEVEDiqI45y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#fix bounding box(multiply by 2, check negative values , values bigger than  size image)\n",
        "max_vals = [1920, 1920, 1080, 1080]\n",
        "for idx, col in enumerate(['xmin', 'xmax', 'ymin', 'ymax']):\n",
        "    df_dataset[col] = df_dataset[col].astype(float)\n",
        "    df_dataset[col] = df_dataset[col]*2\n",
        "    df_dataset.loc[df_dataset[col] < 0, col] = 0\n",
        "    df_dataset.loc[df_dataset[col] > max_vals[idx]-2, col ]= max_vals[idx]-2\n",
        "    df_dataset[col] = df_dataset[col].astype(int)\n",
        "\n",
        "\n",
        "df_dataset.head()"
      ],
      "metadata": {
        "id": "UZpybVACIvGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print min max values\n",
        "for col in  ['xmin', 'xmax', 'ymin', 'ymax']:\n",
        "  print(f'{col}: {df_dataset[col].min()} {df_dataset[col].max()}')"
      ],
      "metadata": {
        "id": "5vCUM22-w0zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Remove rare classes"
      ],
      "metadata": {
        "id": "VgDMOp03M8_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_dataset['name'].value_counts().plot(kind='bar')"
      ],
      "metadata": {
        "id": "GJRNrfkyNSvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove BAD_STREETLIGHT class as there is only one item\n",
        "df_dataset = df_dataset.groupby('name').filter(lambda x: len(x)  >1)\n",
        "\n",
        "#define class after removed\n",
        "df_dataset['name'].value_counts()\n",
        "classes_after_remove = df_dataset.name.unique().tolist()\n",
        "classes_after_remove\n",
        "\n"
      ],
      "metadata": {
        "id": "E-NZfhkPNAP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_map_label_after_remove = {idx: clc for idx, clc in enumerate(classes_after_remove)}\n",
        "class_map_label_after_remove"
      ],
      "metadata": {
        "id": "oXISEJyuNF9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_map_class_after_remove = {clc: idx for idx, clc in enumerate(classes_after_remove)}\n",
        "label_map_class_after_remove"
      ],
      "metadata": {
        "id": "_JtUDM2nNGgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Plot images with labels and bounding box"
      ],
      "metadata": {
        "id": "s0UcLf-zIuDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_label_box = {}\n",
        "for row in tqdm(df_dataset.iterrows(),total=len(df_dataset)):\n",
        "    info = row[1]\n",
        "    xmax, xmin, ymax, ymin = info['xmax'], info['xmin'], info['ymax'], info['ymin']\n",
        "    image_path = info['image_path']\n",
        "    \n",
        "    dataset_label_box[image_path] = dataset_label_box.get(image_path,[])\n",
        "    dataset_label_box[image_path].append((info['class'], info['name'], [xmin, ymin, xmax, ymax]))\n",
        "dataset_label_box;"
      ],
      "metadata": {
        "id": "jZJDXNZUItWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plotImagesAndLabels(dataset_path,dataset_filenames,dataset_label_box);"
      ],
      "metadata": {
        "id": "LxYvsR5OJF83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Split images to valid and train"
      ],
      "metadata": {
        "id": "0h6Fah7oLkPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "images_pathes = df_dataset.image_path.unique()\n",
        "train_image_pathes, valid_image_pathes = train_test_split(images_pathes, test_size=0.10, random_state=42)\n"
      ],
      "metadata": {
        "id": "85DvtxB0LmnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check classes distribution in train and valid\n",
        "for cls in label_map_class_after_remove.keys():\n",
        "  cls_train = len(df_dataset[(df_dataset.image_path.isin(train_image_pathes)) & (df_dataset.name == cls)])\n",
        "  cls_valid = len(df_dataset[(df_dataset.image_path.isin(valid_image_pathes)) & (df_dataset.name == cls)])\n",
        "  print(f\"{cls}: train: {cls_train} valid {cls_valid}\")"
      ],
      "metadata": {
        "id": "UI40MxZA8z6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create folder for train , test and  valid dataset deponding  on yolo format\n",
        "if os.path.isdir('/content/custom_data/'):\n",
        "    shutil.rmtree('/content/custom_data/')\n",
        "custom_data_path='/content/custom_data/';\n",
        "os.makedirs(custom_data_path, exist_ok=True)\n",
        "\n",
        "labels_path_test=custom_data_path + 'test/labels/';\n",
        "images_path_test=custom_data_path + 'test/images/';\n",
        "os.makedirs(labels_path_test, exist_ok=True)\n",
        "os.makedirs(images_path_test, exist_ok=True)\n",
        "\n",
        "labels_path_train=custom_data_path + 'train/labels/';\n",
        "images_path_train=custom_data_path + 'train/images/';\n",
        "os.makedirs(labels_path_train, exist_ok=True)\n",
        "os.makedirs(images_path_train, exist_ok=True)\n",
        "\n",
        "labels_path_valid=custom_data_path + 'valid/labels/';\n",
        "images_path_valid=custom_data_path+ 'valid/images/';\n",
        "os.makedirs(labels_path_valid, exist_ok=True)\n",
        "os.makedirs(images_path_valid, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "PfvslV_4UapN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copy valid images\n",
        "df_valid = df_dataset[(df_dataset.image_path.isin(valid_image_pathes))]\n",
        "create_dataset(df_valid,images_path_valid,labels_path_valid,dataset_path,label_map_class_after_remove)"
      ],
      "metadata": {
        "id": "z5YTXJRyZVn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copy train  images\n",
        "df_train = df_dataset[(df_dataset.image_path.isin(train_image_pathes))]\n",
        "create_dataset(df_train,images_path_train,labels_path_train,dataset_path,label_map_class_after_remove)"
      ],
      "metadata": {
        "id": "FrbQKsP_WyAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copy test  images\n",
        "create_dataset(df_test,images_path_test,labels_path_test,dataset_path)\n",
        "_, _, files = next(os.walk('/content/custom_data/test/images'))\n",
        "file_count = len(files)\n",
        "file_count"
      ],
      "metadata": {
        "id": "7GMCDf1tUGWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install Dependency Yolo\n",
        "\n"
      ],
      "metadata": {
        "id": "juya6CS8bZVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/SkalskiP/yolov7.git\n",
        "%cd yolov7\n",
        "!git checkout fix/problems_associated_with_the_latest_versions_of_pytorch_and_numpy\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "rJ21Bih9NeRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train Models"
      ],
      "metadata": {
        "id": "NVUNflxlcs5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/yolov7"
      ],
      "metadata": {
        "id": "G16sWbBsT_Zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download COCO starting checkpoint\n",
        "%cd /content/yolov7\n",
        "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt"
      ],
      "metadata": {
        "id": "IwPIF0LwFer2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#yaml file depending on yolo format\n",
        "import os\n",
        "import yaml\n",
        "\n",
        "config = {\n",
        "   'train':'/content/custom_data/train/images',\n",
        "    'val': '/content/custom_data/valid/images' ,\n",
        "    'nc': len(classes_after_remove),\n",
        "    'names':  classes_after_remove\n",
        "}\n",
        " \n",
        "with open(os.path.join(\"data/\", \"custom_data.yaml\"), \"w\") as file:\n",
        "    yaml.dump(config, file, default_flow_style=False)"
      ],
      "metadata": {
        "id": "cXxy-s7jcvPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##change lr and lf"
      ],
      "metadata": {
        "id": "WHYs6epGdwhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/yolov7/data/hyp.scratch.custom.yaml\n",
        "\n",
        "lr0: 0.001  # initial learning rate (SGD=1E-2, Adam=1E-3)\n",
        "lrf: 0.01  # final OneCycleLR learning rate (lr0 * lrf)\n",
        "momentum: 0.937  # SGD momentum/Adam beta1\n",
        "weight_decay: 0.0005  # optimizer weight decay 5e-4\n",
        "warmup_epochs: 3.0  # warmup epochs (fractions ok)\n",
        "warmup_momentum: 0.8  # warmup initial momentum\n",
        "warmup_bias_lr: 0.1  # warmup initial bias lr\n",
        "box: 0.05  # box loss gain\n",
        "cls: 0.3  # cls loss gain\n",
        "cls_pw: 1.0  # cls BCELoss positive_weight\n",
        "obj: 0.7  # obj loss gain (scale with pixels)\n",
        "obj_pw: 1.0  # obj BCELoss positive_weight\n",
        "iou_t: 0.20  # IoU training threshold\n",
        "anchor_t: 4.0  # anchor-multiple threshold\n",
        "# anchors: 3  # anchors per output layer (0 to ignore)\n",
        "fl_gamma: 0.0  # focal loss gamma (efficientDet default gamma=1.5)\n",
        "hsv_h: 0.015  # image HSV-Hue augmentation (fraction)\n",
        "hsv_s: 0.7  # image HSV-Saturation augmentation (fraction)\n",
        "hsv_v: 0.4  # image HSV-Value augmentation (fraction)\n",
        "degrees: 0.0  # image rotation (+/- deg)\n",
        "translate: 0.2  # image translation (+/- fraction)\n",
        "scale: 0.5  # image scale (+/- gain)\n",
        "shear: 0.0  # image shear (+/- deg)\n",
        "perspective: 0.0  # image perspective (+/- fraction), range 0-0.001\n",
        "flipud: 0.0  # image flip up-down (probability)\n",
        "fliplr: 0.5  # image flip left-right (probability)\n",
        "mosaic: 1.0  # image mosaic (probability)\n",
        "mixup: 0.0  # image mixup (probability)\n",
        "copy_paste: 0.0  # image copy paste (probability)\n",
        "paste_in: 0.0  # image copy paste (probability), use 0 for faster training\n",
        "loss_ota: 1 # use ComputeLossOTA, use 0 for faster training"
      ],
      "metadata": {
        "id": "ukpigpnTgtUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#disable wandb else enable if you want to monitor training\n",
        "!pip install wandb\n",
        "!wandb disabled"
      ],
      "metadata": {
        "id": "LW1AAQRgkMbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #If you want to train model please change value of variable(IS_Training) to True and run this cellto begin training\n",
        "if IS_Training :\n",
        "    !python train.py  --batch-size 8 \\\n",
        "                    --epoch 30 \\\n",
        "                    --data /content/yolov7/data/custom_data.yaml \\\n",
        "                    --img 640 640 \\\n",
        "                    --cfg cfg/training/yolov7.yaml \\\n",
        "                    --weights 'yolov7_training.pt' \\\n",
        "                    --name yolov7 \\\n",
        "                    --hyp data/hyp.scratch.custom.yaml \\\n",
        "                    --save_period 1 \\\n",
        "                      --workers 8      \\\n",
        "                      --project /content/gdrive/MyDrive/Yolox7 \\\n",
        "                    --freeze  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30"
      ],
      "metadata": {
        "id": "KdZuVGQdf691"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluation"
      ],
      "metadata": {
        "id": "CeSC_yYibkDq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###evaluate.py file"
      ],
      "metadata": {
        "id": "NrMNcI3ZczkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile detect.py\n",
        "import argparse\n",
        "import time\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "from numpy import random\n",
        "\n",
        "from models.experimental import attempt_load\n",
        "from utils.datasets import LoadStreams, LoadImages\n",
        "from utils.general import check_img_size, check_requirements, check_imshow, non_max_suppression, apply_classifier, \\\n",
        "    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path\n",
        "from utils.plots import plot_one_box\n",
        "from utils.torch_utils import select_device, load_classifier, time_synchronized, TracedModel\n",
        "\n",
        "\n",
        "def detect(save_img=False):\n",
        "    source, weights, view_img, save_txt, imgsz, trace = opt.source, opt.weights, opt.view_img, opt.save_txt, opt.img_size, not opt.no_trace\n",
        "    save_img = not opt.nosave and not source.endswith('.txt')  # save inference images\n",
        "    webcam = source.isnumeric() or source.endswith('.txt') or source.lower().startswith(\n",
        "        ('rtsp://', 'rtmp://', 'http://', 'https://'))\n",
        "\n",
        "    # Directories\n",
        "    save_dir = Path(increment_path(Path(opt.project) / opt.name, exist_ok=opt.exist_ok))  # increment run\n",
        "    (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n",
        "    #print(f\"  save_dir is saved in: {save_dir}\")\n",
        "    # Initialize\n",
        "    set_logging()\n",
        "    device = select_device(opt.device)\n",
        "    half = device.type != 'cpu'  # half precision only supported on CUDA\n",
        "\n",
        "    # Load model\n",
        "    model = attempt_load(weights, map_location=device)  # load FP32 model\n",
        "    stride = int(model.stride.max())  # model stride\n",
        "    imgsz = check_img_size(imgsz, s=stride)  # check img_size\n",
        "\n",
        "    if trace:\n",
        "        model = TracedModel(model, device, opt.img_size)\n",
        "\n",
        "    if half:\n",
        "        model.half()  # to FP16\n",
        "\n",
        "    # Second-stage classifier\n",
        "    classify = False\n",
        "    if classify:\n",
        "        modelc = load_classifier(name='resnet101', n=2)  # initialize\n",
        "        modelc.load_state_dict(torch.load('weights/resnet101.pt', map_location=device)['model']).to(device).eval()\n",
        "\n",
        "    # Set Dataloader\n",
        "    vid_path, vid_writer = None, None\n",
        "    if webcam:\n",
        "        view_img = check_imshow()\n",
        "        cudnn.benchmark = True  # set True to speed up constant image size inference\n",
        "        dataset = LoadStreams(source, img_size=imgsz, stride=stride)\n",
        "    else:\n",
        "        dataset = LoadImages(source, img_size=imgsz, stride=stride)\n",
        "\n",
        "    # Get names and colors\n",
        "    names = model.module.names if hasattr(model, 'module') else model.names\n",
        "    colors = [[random.randint(0, 255) for _ in range(3)] for _ in names]\n",
        "#   submite file\n",
        "    orginal_classes = ['GRAFFITI',\n",
        "            'FADED_SIGNAGE',\n",
        "            'POTHOLES',                                                                                                                                                    \n",
        "            'GARBAGE',\n",
        "            'CONSTRUCTION_ROAD',\n",
        "            'BROKEN_SIGNAGE',\n",
        "            'BAD_STREETLIGHT',\n",
        "            'BAD_BILLBOARD',\n",
        "            'SAND_ON_ROAD',\n",
        "            'CLUTTER_SIDEWALK',\n",
        "            'UNKEPT_FACADE'\n",
        "        ]\n",
        "\n",
        "\n",
        "    class_orginal_class = {clc: idx for idx, clc in enumerate(orginal_classes)}\n",
        "    df_submission =pd.DataFrame([], columns=['class', 'image_path','name','xmax','xmin','ymax','ymin'])\n",
        "    # Run inference\n",
        "    if device.type != 'cpu':\n",
        "        model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))  # run once\n",
        "    old_img_w = old_img_h = imgsz\n",
        "    old_img_b = 1\n",
        "\n",
        "    t0 = time.time()\n",
        "    for path, img, im0s, vid_cap in dataset:\n",
        "        #print(path.split('/')[-1])\n",
        "        img = torch.from_numpy(img).to(device)\n",
        "        img = img.half() if half else img.float()  # uint8 to fp16/32\n",
        "        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
        "        if img.ndimension() == 3:\n",
        "            img = img.unsqueeze(0)\n",
        "\n",
        "        # Warmup\n",
        "        if device.type != 'cpu' and (old_img_b != img.shape[0] or old_img_h != img.shape[2] or old_img_w != img.shape[3]):\n",
        "            old_img_b = img.shape[0]\n",
        "            old_img_h = img.shape[2]\n",
        "            old_img_w = img.shape[3]\n",
        "            for i in range(3):\n",
        "                model(img, augment=opt.augment)[0]\n",
        "\n",
        "        # Inference\n",
        "        t1 = time_synchronized()\n",
        "        with torch.no_grad():   # Calculating gradients would cause a GPU memory leak\n",
        "            pred = model(img, augment=opt.augment)[0]\n",
        "        t2 = time_synchronized()\n",
        "\n",
        "        # Apply NMS\n",
        "        pred = non_max_suppression(pred, opt.conf_thres, opt.iou_thres, classes=opt.classes, agnostic=opt.agnostic_nms)\n",
        "        t3 = time_synchronized()\n",
        "\n",
        "        # Apply Classifier\n",
        "        if classify:\n",
        "            pred = apply_classifier(pred, modelc, img, im0s)\n",
        "\n",
        "        # Process detections\n",
        "        for i, det in enumerate(pred):  # detections per image\n",
        "            if webcam:  # batch_size >= 1\n",
        "                p, s, im0, frame = path[i], '%g: ' % i, im0s[i].copy(), dataset.count\n",
        "            else:\n",
        "                p, s, im0, frame = path, '', im0s, getattr(dataset, 'frame', 0)\n",
        "           # print(f'p.name {p.name}')\n",
        "            p = Path(p)  # to Path\n",
        "            save_path = str(save_dir / p.name)  # img.jpg\n",
        "            txt_path = str(save_dir / 'labels' / p.stem) + ('' if dataset.mode == 'image' else f'_{frame}')  # img.txt\n",
        "            gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n",
        "            if len(det):\n",
        "                # Rescale boxes from img_size to im0 size\n",
        "                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n",
        "\n",
        "                # Print results\n",
        "                for c in det[:, -1].unique():\n",
        "                    n = (det[:, -1] == c).sum()  # detections per class\n",
        "                    s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n",
        "\n",
        "                # Write results\n",
        "                confice=0;\n",
        "                index=0\n",
        "                res=[]\n",
        "                #print(reversed(det))\n",
        "                for k in reversed(det):\n",
        "              \n",
        "                        *xyxy, conf, cls = k\n",
        "                        # label = f'{names[int(cls)]} {conf:.2f}'\n",
        "                        x=xyxy\n",
        "                        c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n",
        "                        df_submission=df_submission.append({'class':int(class_orginal_class[names[int(cls)]]), 'image_path':path.split('/')[-1], 'name':names[int(cls)],'xmax':int(x[2]/2),'xmin':int(x[0]/2),'ymax':int(x[3]/2),'ymin':int(x[1]/2) }, ignore_index=True)\n",
        "\n",
        "\n",
        "            else :\n",
        "                        df_submission=df_submission.append({'class':'', 'image_path':path.split('/')[-1], 'name':'','xmax':'','xmin':'','ymax':'','ymin':'' }, ignore_index=True)\n",
        "\n",
        "                 # Stream results\n",
        "            if view_img:\n",
        "                cv2.imshow(str(p), im0)\n",
        "                cv2.waitKey(1)  # 1 millisecond\n",
        "\n",
        "            # Save results (image with detections)\n",
        "           \n",
        "\n",
        "    if save_txt or save_img:\n",
        "        s = f\"\\n{len(list(save_dir.glob('labels/*.txt')))} labels saved to {save_dir / 'labels'}\" if save_txt else ''\n",
        "        print(f\"Results saved to {save_dir}{s}\")\n",
        "\n",
        "    #print(f'Done. ({time.time() - t0:.3f}s)')\n",
        "    df_submission.to_csv('/content/submission.csv',index=False)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--weights', nargs='+', type=str, default='yolov7.pt', help='model.pt path(s)')\n",
        "    parser.add_argument('--source', type=str, default='inference/images', help='source')  # file/folder, 0 for webcam\n",
        "    parser.add_argument('--img-size', type=int, default=640, help='inference size (pixels)')\n",
        "    parser.add_argument('--conf-thres', type=float, default=0.25, help='object confidence threshold')\n",
        "    parser.add_argument('--iou-thres', type=float, default=0.45, help='IOU threshold for NMS')\n",
        "    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')\n",
        "    parser.add_argument('--view-img', action='store_true', help='display results')\n",
        "    parser.add_argument('--save-txt', action='store_true', help='save results to *.txt')\n",
        "    parser.add_argument('--save-conf', action='store_true', help='save confidences in --save-txt labels')\n",
        "    parser.add_argument('--nosave', action='store_true', help='do not save images/videos')\n",
        "    parser.add_argument('--classes', nargs='+', type=int, help='filter by class: --class 0, or --class 0 2 3')\n",
        "    parser.add_argument('--agnostic-nms', action='store_true', help='class-agnostic NMS')\n",
        "    parser.add_argument('--augment', action='store_true', help='augmented inference')\n",
        "    parser.add_argument('--update', action='store_true', help='update all models')\n",
        "    parser.add_argument('--project', default='runs/detect', help='save results to project/name')\n",
        "    parser.add_argument('--name', default='exp', help='save results to project/name')\n",
        "    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')\n",
        "    parser.add_argument('--no-trace', action='store_true', help='don`t trace model')\n",
        "    opt = parser.parse_args()\n",
        "    print(opt)\n",
        "    #check_requirements(exclude=('pycocotools', 'thop'))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        if opt.update:  # update all models (to fix SourceChangeWarning)\n",
        "            for opt.weights in ['yolov7.pt']:\n",
        "                detect()\n",
        "                strip_optimizer(opt.weights)\n",
        "        else:\n",
        "            detect()"
      ],
      "metadata": {
        "id": "-dqNJWnzbxSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###detect"
      ],
      "metadata": {
        "id": "QwORCECFdXji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Download pretrained model, https://medium.com/@acpanjan/download-google-drive-files-using-wget-3c2c025a8b99\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=15gZladqILTKQCZr1S2oLdWp1970T7kCy' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=15gZladqILTKQCZr1S2oLdWp1970T7kCy\" -O best.pt && rm -rf /tmp/cookies.txt"
      ],
      "metadata": {
        "id": "mnyXbbfsc925"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "15gZladqILTKQCZr1S2oLdWp1970T7kCy\n",
        "15gZladqILTKQCZr1S2oLdWp1970T7kCy\n",
        "15gZladqILTKQCZr1S2oLdWp1970T7kCy\n",
        "https://drive.google.com/file/d/15gZladqILTKQCZr1S2oLdWp1970T7kCy/view?usp=share_link"
      ],
      "metadata": {
        "id": "7T4Mtbaada52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights 'best.pt' --img-size 640 --source /content/custom_data/test/images  --conf 0.3"
      ],
      "metadata": {
        "id": "Aeoyef4AdAmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# after run this cell,  submission file will be downloaded\n",
        "import numpy as np\n",
        "def expand_bb(row, ratio=1.05):\n",
        "  #Expand bounding box by ratio\n",
        "  xmin, xmax, ymin, ymax = row['xmin'], row['xmax'], row['ymin'], row['ymax']\n",
        "  if np.isnan(xmin):\n",
        "    return row\n",
        "  xc = (xmin+xmax)//2\n",
        "  yc = (ymin+ymax)//2\n",
        "  xmin = xc - ratio * (xmax-xmin) //2\n",
        "  xmax = xc + ratio * (xmax-xmin) //2\n",
        "  ymin = yc - ratio * (ymax-ymin) //2\n",
        "  ymax =  yc + ratio * (ymax-ymin) //2\n",
        "  row['xmin'] = max(int(xmin), 0)\n",
        "  row['xmax'] = min(int(xmax), 1920//2)\n",
        "  row['ymin'] = max(int(ymin), 0)\n",
        "  row['ymax'] = min(int(ymax), 1920//2)\n",
        "  return row\n",
        "\n",
        "df = pd.read_csv(\"/content/submission.csv\")\n",
        "df2 = df.copy()\n",
        "df2 = df2.apply(expand_bb, axis=1)\n",
        "df2.to_csv(\"/content/submission_expand_bb.csv\", index=False)\n",
        "from google.colab import files\n",
        "files.download('/content/submission_expand_bb.csv')"
      ],
      "metadata": {
        "id": "O1IcB-qLdKVr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}